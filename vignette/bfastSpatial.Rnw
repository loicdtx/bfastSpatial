\documentclass{article}

\usepackage{hyperref}

\def\code#1{\texttt{#1}}

\begin{document}

\title{bfastSpatial}
\author{Lo\"{i}c Dutrieux, Ben DeVries, Jan Verbesselt}

\maketitle

\section{Preamble}
The \code{bfastSpatial} provides utilities to performs change detection analysis on time-series of spatial gridded data, such as time-series of remote sensing images (Landsat, MODIS and the likes). The tools provided by \code{bfastSpatial} allows a user to perform all the steps of the change detection workflow, from pre-processing raw surface reflectance Landsat data, inventorying and preparing them for analysis to the production and formatting of change detection results. The present document aims at providing guidance to the users of \code{bfastSpatial} by detailing every steps of the process.

\section{Set up your system}
\subsection{Windows}
There are no specific system requirements for Windows, besides having (a recent version of) R installed; installing the \code{bfastSpatial} package will automatically install the required dependencies.  
\subsection{Linux & Mac}
Some pre-processing functions require the \code{rgdal} package, which is a binding between the gdal library and R. For \code{rgdal} to work on Linux and Mac systems, gdal should be installed and properly set-up. For that, please refer to the web page of the \href{http://www.gdal.org/}{gdal project} as well as \href{http://cran.r-project.org/web/packages/rgdal/index.html}{rgdal}.

\section{Downloading Landsat data from Earth Explorer}
Working with Landsat time-series often involve downloading large amount of data. The full Landsat archive for one path/row may very well exceed 500 scenes in some parts of the world. The most common way to access the data is via the \href{http://earthexplorer.usgs.gov/}{Earth Explorer platform}. You need to have an account before being able to request data to be pre-processed.
\subsection{Placing your order}
USGS is planning to support the delivery of data in different formats (HDF, GeoTiff, binary). GeoTiff is a common and easy to handle format of raster data and should be your preferred choice if you are working in Windows.
\subsection{Downloading the data}
Once you receive the e-mail from USGS notifying you that your order has been pre-processed, you will be able to proceed to the download of the data. Because the amount of scenes is usually large, the use of a download manager is highly recommended. Two options:
\begin{itemize}
\item The Bulk Download Application
\item The DownloadThemAll pluggin of the firefox browser
\end{itemize}


\section{Data pre-processing}
The \code{bfastSpatial} package includes utilities to pre-process Landsat surface reflectance data and prepare them for subsequent analysis with the change detection functions such as \code{bfmSpatial}. The overall Landsat pre-processing requires to:
\begin{itemize}
\item Extract data from the tar.gz archive
\item Calculate Vegetation Indices from surface reflectance bands (when not provided by USGS)
\item Crop the data to a desired spatial extent
\item Apply one of the cloud/land mask supplied with the data
\item Create a the spatio-temporal object to be used in subsequent analyses
\end{itemize}

The two important functions to perform the above mentioned steps are \code{processLandsat} and \code{processLandsatBatch}. The former is a wrapper that performs the above steps sequentially, automatically generating file names and deleting unnecessary intermediary outputs. The latter (\code{processLandsatBatch}) allows a user to run \code{processLandsat} in batch mode, over several scenes, with parallel support. Several vegetation indices are supported by both \code{processLandsat} and \code{processLandsatBatch}.
Let's illustrate that with an example.


% TODO add example here

Once the vegetation index layers have been produced for several dates, they can be stacked, in order to create a multilayer raster object, with time dimention written in the file as well. The function to perform this operation on Landsat data is the \code{timeStack} function. By simply providing a list of file names or a directory containing the files, the function will create a multilayer object and directly parse through the file names to extract temporal information from them and write that information to the object created.

% TODO add timeStack example here



\section{Data Inventory}

A number of functions are available in the bfastSpatial package to help keep an inventory of data in a raster time series stack. These functions range from basic scene information (\code{getSceneinfo()}) to summary of pixel values per year in the time series (\code{annualSummary()}).

The following functions are included in the Data Inventory module:
\begin{enumerate}
\item \code{getSceneinfo()}
\item \code{countObs()}
\item \code{annualSummary()}
\end{enumerate}

\subsection{Basic Scene Information: \code{getSceneinfo()}}

\code{getSceneinfo()} allows the user to list the information contained within a scene ID. Currently, only Landsat scene ID's are supported. For example, the scene ID "LE71700552007309ASN00" tells us that the scene is from the Landsat 7 ETM+ sensor ('LE7'), path-row 170-55 ('170055') and was acquired on the 309th day of the year 2007 ('2007309'). Calling \code{getSceneinfo('LE71700552007309ASN00')} will give a data.frame with one row showing all of this information.

<<echo=FALSE, results='hide'>>=
library(bfastSpatial)
@

<<>>=
getSceneinfo('LE71700552007309ASN00')
@

When working with Landsat data, it is a good idea to assign and keep these sceneID's as layer names (see \code{?raster::names}) so the relevant information is associated to each raster layer.

<<>>=
# show scene info from tura layers
data(tura)
head(names(tura))
s <- getSceneinfo(names(tura))
head(s)
# add a column for years and plot # of scenes per year
s$year <- as.numeric(substr(s$date, 1, 4))
hist(s$year, breaks=c(1984:2014), main="p170r55: Scenes per Year", xlab="year", ylab="# of scenes")
@

We can combine the dates and sensor information to get more of an idea of where our data are coming from.

<<>>=
library(ggplot2)
p <- ggplot(data = s, aes(x = year))
p <- p + geom_bar(aes(fill = sensor), binwidth=1, col="black")
p <- p + labs(y="number of scenes")
p
@

More examples can be found under \code{?getSceneinfo}. Many other functions in the bfastSpatial package rely on getSceneinfo to extract relevant scene information, such as acquisition dates to be passed to \code{bfmSpatial()} or \code{bfmPixel()}.

\subsection{Valid Observations: \code{countObs()}}

The number of available observations in a raster time series can be calculated by using countObs(). This function "drills" through pixels of a time series and counts the number of pixels with a non-NA value. Optionally, any other value can be supplied as a substitute for NA (e.g. the number of non-zero values per pixel can also be queried). Values can also be expressed as a percentage if as.perc is set to TRUE.

<<>>=
data(tura)
obs <- countObs(tura, as.perc=TRUE)
plot(obs)
summary(obs)
@

\subsection{Annual Summary Statistics: \code{annualSummary()}}

\section{Spatial BFASTMonitor}

\subsection{Working with pixels: \code{bfmPixel}}

Working with BFM can be intimidating at first, especially given the number of parameters that need to be set (or at least considered) before running the algorithm. It is important to understand these parameters, as not all raster time series are equal. Some time series may have frequent and large temporal gaps (as can be expected in some tropical forest), while others are temporally dense. These differences may call for slightly different approaches in implementing BFM.

\code{bfmPixel} is a function which queries individual pixels in a raster time series and runs bfm over that pixel's time series. To run \code{bfmPixel} in interactive mode, one of the layers of the time series needs to first be plotted.

<<eval=FALSE>>=
# load tura RasterBrick
data(tura)
# plot the 6h layer
plot(tura, 6)
# run bfmPixel() in interactive mode with a monitoring period starting @ the 1st day in 2009
bfm <- bfmPixel(tura, start=c(2009, 1), interactive=TRUE)
@

Inspecting the output of this function, you will see that a list of length 2 has been outputted. First, a list of class \code{bfastmonitor} is output under \code{$bfm}. Second, an integer indicating the cell number that has been clicked is output under \code{$cell}. The output is formatted this way so that if \code{bfmPixel} is run in interactive mode, a follow-up analysis can be done on that same cell without having to guess which cell was clicked before. In the above example, the cell number can be retrieved simply by typing \code{bfm$cell} in the console.

Let's run \code{bfmPixel} again, but this time indicating a specific cell number instead of using interactive mode. Note that by default \code{interactive=FALSE}, so there is no need to specify this if a value for \code{cell} is given.

<<>>=
targcell <- 1000
bfm <- bfmPixel(tura, cell=targcell, start=c(2009, 1))
# inspect and plot the $bfm output
bfm$bfm
plot(bfm$bfm)
@

Specifying a cell number gives the advantage of being able to test different parameters on the same pixel time series to see what impact these parameters have on the sensitivity of the algorithm.

<<>>=
# use a harmonic model only
bfm1 <- bfmPixel(tura, cell=targcell, start=c(2009, 1), formula=response~harmon)
plot(bfm1$bfm)
# same, but with an order of 1
bfm2 <- bfmPixel(tura, cell=targcell, start=c(2009, 1), formula=response~harmon, order=1)
plot(bfm2$bfm)
# only trend
bfm3 <- bfmPixel(tura, cell=targcell, start=c(2009, 1), formula=response~trend)
plot(bfm3$bfm)
@

Check out \code{?bfastmonitor} for more information on the parameters that are included in the method.

A number of additional options are provided in \code{bfmPixel}. Specifying a value for \code{monend} will trim the time series after that date (thus limiting the monitoring period to a given period). This simple modification can have an impact on the resulting change magnitude, which is computed as the median residual between the predicted and observed values within the monitoring period.

<<>>=
# bfmPixel using a 1-year monitoring period
bfm4 <- bfmPixel(tura, cell=targcell, start=c(2009, 1), monend=c(2010, 1))
plot(bfm4$bfm)
@

Finally, for Landsat time series the analysis can be limited to data of a specific sensor. The \code{sensor} parameter currently accepts the following possible character values:
\begin{itemize}
\item \code{"ETM+"}
\item \code{"ETM+ SLC-on"}
\item \code{"ETM+ SLC-off"}
\item \code{"TM"}
\end{itemize}

<<>>=
# apply bfmPixel only on ETM+ data
bfm5 <- bfmPixel(tura, start=c(2009, 1), sensor="ETM+")
plot(bfm5$bfm)
@

\subsection{Working with raster time series: \code{bfmSpatial}}

Now that we have done some pixel-based testing, it is time to apply \code{bfastmonitor} over an entire raster time series. This will allow us to pinpoint the location and timing of changes in our study area. In the previous section, we saw that there was a large gap in the 1990's in the tura raster time series, and given the acceptable data density, we could just limit the analysis to ETM+ data. We also saw that a harmonic-trend model with an order of 1 seemed to be the most reasonable time series model for the tura dataset. We will pass these same arguments to \code{bfmSpatial}. At the same time, we will calculate how long the process takes by wrapping it in a \code{system.time} call.

<<echo=FALSE, results='hide'>>=
if(!file.exists("temp/bfmTura.rda")){
    # run bfmSpatial over tura for a monitoring period of 2009 -
    bfm <- bfmSpatial(tura, start=c(2009, 1), order=1)
} else {
    load("temp/bfmTura.rda")
}
@

<<eval=FALSE>>=
# run bfmSpatial over tura for a monitoring period of 2009 -
t1 <- system.time(
    bfm <- bfmSpatial(tura, start=c(2009, 1), order=1)
    )
# plot the result
plot(bfm)
@

Luckily for us, tura is a very small RasterBrick, and processing is not incredibly time consuming. Realistically, analyses are done over significantly larger areas (possibly extending beyond a single scene), so running \code{bfmSpatial} on such large areas quickly becomes a very time-consuming task. To assist in this, multi-core support has been built into \code{bfmSpatial}, using the \code{parallel} package. Let's run the same line of code again, but this time specify a value for \code{mc.cores}, which will distribute the process over that many cpus. Again, we will wrap the code in a \code{system.time} call to test the speed of the processing.

<<eval=FALSE>>=
t2 <- system.time(
    bfm <- bfmSpatial(tura, start=c(2009, 1), order=1, mc.cores=8)
    )
# compare processing time with previous run
t1 - t2
@

%% option: include something from parallel package regarding checking # of available cores, etc...?
%% or something like 'good practices in parallel computing'? Or could that be covered in the pre-processing module?

\section{Post-Processing of BFM output}

Three raster layers are output by \code{bfmSpatial}:
\begin{enumerate}
\item breakpoint timing - in decimal year format
\item change magnitude - the medial residual between expected and observed values in the monitoring period
\item error flag - possible values of 1 if an error has been encountered in a particular pixel, and NA where the algorithm was successful (or a mask had already been applied previously)
\end{enumerate}

The \code{bfastSpatial} package has some simple functions for 'unpacking' the \code{bfmSpatial} results. \code{bfmChange} simply extracts the first layer and saves it to a separate object.

<<>>=
# extract change raster
change <- bfmChange(bfm)
@

The change raster gives breakpoint timing values in decimal years. A better way to map change timing from these results may be to show the month of change (the validity of this depends on the temporal density of there input time series). \code{changeMonth} is a convenient way to convert breakpoint values to change months. The result is one or more raster layers with integer values between 1 and 12, representing the months of the year. In cases where multiple years are represented in the change raster, these are split into raster layers representing one layer per year.

<<>>=
months <- changeMonth(change)
# set up labels and colourmap for months
monthlabs <- c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")
library(RColorBrewer)
cols <- rev(brewer.pal(11, "RdYlBu"))
# interpolate colormap (since max # of colours for "RdYlBu" is 11)
cols <- colorRampPalette(cols)(12)
plot(months, col=cols, breaks=c(1:12), legend=FALSE)
# insert legend
legend("bottomright", legend=monthlabs, cex=0.5, fill=cols, ncol=2)
@

\code{bfmMagn} does the same as \code{bfmChange} to the second layer, but adds some other options (masking by breakpoint, applying a threshold). Magnitude is computed as the median residual between expected and observed values throughout the \emph{entire} monitoring period, meaning that all pixels are assigned a value regardless of whether or not a breakpoint has been detected. If we are only interested in looking at pixels where a breakpoint has been detected, we can use the \code{change} argument in the \code{bfmMagn}, which takes a raster of breakpoints to use as a filter.

<<>>=
# extract magn raster, and include only change pixels
magn <- bfmMagn(bfm, change=change)
# compare with 'original' magn raster
op <- par(mfrow=c(1, 2))
plot(magn, main="Magnitude: breakpoints")
plot(bfm[[2]], main="Magnitude: all pixels")
par(op)
@

Note that the magnitude values are in the same scale as the input data, which had been scaled by 10000. Scaling back can be done by simple raster algebra, or with the \code{raster::calc} function to enable writing to file.

<<>>=
magn <- bfmMagn(bfm, change=change) / 10000
@

The magnitude could be used to discriminate between actual deforestation and other factors that might give rise to breakpoints (such as noisy data). However, interpreting magnitude is complicated by the fact that follow-up dynamics can affect the magnitude value, since it is computed throughout the entire monitoring period. To circumvent this (not entirely), we will re-run \code{bfmSpatial} using a 1-year monitoring period, under the assumption that this monitoring window is too short for post-change dynamics to significantly affect the magnitude value. To do this, we will include the \code{monend} argument of \code{bfmSpatial}, which will limit the analysis to a specific time period. In this example, we will use a 2009-2010 monitoring period with all other parameters the same as above.

<<echo=FALSE, results='hide'>>=
if(!file.exists("temp/bfmTura09.rda")){
    bfm09 <- bfmSpatial(tura, start=c(2009, 1), monend=c(2010, 1), order=1)
} else {
    load("temp/bfmTura09.rda")
}
# extract change
change09 <- bfmChange(bfm09)
# extract and rescale magnitude
magn09 <- bfmMagn(bfm09, change=change09) / 10000
@

<<eval=FALSE>>=
bfm09 <- bfmSpatial(tura, start=c(2009, 1), monend=c(2010, 1), order=1)
# extract change
change09 <- bfmChange(bfm09)
# extract and rescale magnitude
magn09 <- bfmMagn(bfm09, change=change09) / 10000
@

Suppose we know from field observations or other reference data that breakpoints with NDVI magnitudes of -0.05 are associated with high probability of detected actual deforestation. We can easily apply this threshold to our magnitude raster, or even pass this threshold as an additional argument to \code{bfmMagn}. In the later case, take care with the scaling of the data - the original \code{bfmSpatial} results are still in their ``raw" format. In this case, our threshold should be accordingly scaled. In this example, we will scale the final magnitude back, as above.

<<>>=
# extract and rescale magnitude and apply a -500 threshold
magn09thresh <- bfmMagn(bfm09, change=change09, thresh = -500) / 10000
# compare
op <- par(mfrow=c(1, 2))
plot(magn09, main="magnitude")
plot(magn09thresh, main="magnitude < -0.05")
par(op)
@


%% next up:
    %% - bfm on a 1-year monperiod
    %% - apply a magn threshold
    %% - apply an areaSieve (1px, 0.5ha, directions=8 and 4)
    %% - change statistics: clumpSize()

\end{document}